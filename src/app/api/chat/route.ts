import OpenAI from "openai";
import type { ChatCompletionMessageParam } from "openai/resources/chat/completions";
import { prisma } from "@/lib/prisma";
// ç”Ÿæˆå”¯ä¸€ID
function generateId(prefix = '') {
  const timestamp = Date.now().toString(36);
  const random = Math.random().toString(36).substr(2, 9);
  return prefix + timestamp + random;
}
import { getServerSession } from "next-auth";
import { authOptions } from "@/lib/auth";
import { searchMemories, extractMemoriesFromConversation, EmbeddingResult } from "@/lib/embedding";
import { performSemanticSearch, SearchResult } from "@/lib/semantic-search";
import { cache, CACHE_KEYS } from "@/lib/cache";

type ChatMessage = {
  role: "system" | "user" | "assistant";
  content: string;
};

function getOpenAI(): OpenAI {
  return new OpenAI({
    apiKey: process.env.DEEPSEEK_API_KEY || "sk-fe6b55b3677d493cbeac4c8fec658b5e",
    baseURL: "https://api.deepseek.com/v1",
  });
}

export const runtime = "nodejs";

export async function POST(request: Request): Promise<Response> {
  try {
    if (!process.env.DEEPSEEK_API_KEY && !process.env.OPENAI_API_KEY) {
      return new Response(
        JSON.stringify({ error: "ç¼ºå°‘ DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡" }),
        { status: 500 }
      );
    }
    
    // è·å–ç”¨æˆ·ä¼šè¯ï¼ˆä¼˜é›…å¤„ç†é”™è¯¯ï¼‰
    let userId: string | undefined;
    try {
      const session = await getServerSession(authOptions as any);
      userId = ((session as any)?.user as any)?.id || (session as any)?.userId as string | undefined;
      console.log("ğŸ” Chat API - User ID:", userId);
    } catch (error) {
      console.log("âš ï¸ Session error (continuing without user):", error);
      userId = undefined;
    }
    
    const openai = getOpenAI();

    const body = await request.json().catch(() => ({}));
    const messages: ChatMessage[] = Array.isArray(body?.messages)
      ? body.messages.map((msg: any) => ({
          ...msg,
          content: typeof msg.content === 'string' 
            ? msg.content.replace(/[\u0000-\u001F\u007F-\u009F]/g, '') // ç§»é™¤æ§åˆ¶å­—ç¬¦
                .replace(/\\/g, '\\\\') // è½¬ä¹‰åæ–œæ 
                .replace(/"/g, '\\"') // è½¬ä¹‰åŒå¼•å·
                .replace(/\n/g, '\\n') // è½¬ä¹‰æ¢è¡Œç¬¦
                .replace(/\r/g, '\\r') // è½¬ä¹‰å›è½¦ç¬¦
                .replace(/\t/g, '\\t') // è½¬ä¹‰åˆ¶è¡¨ç¬¦
            : msg.content
        }))
      : [];
    const model = (body?.model as string) || process.env.DEEPSEEK_MODEL || "deepseek-chat";
    // æ›´ä¿å®ˆä½†ä¸è‡³äºè¿‡æ—©åœæ­¢ï¼Œç•¥å¢é•¿åº¦
    const temperature = typeof body?.temperature === "number" ? body.temperature : 0.5;
    const stream = Boolean(body?.stream);
    const userLang = (body?.lang as string) || "zh";
    let conversationId: string | undefined = body?.conversationId;
    const web = Boolean(body?.web);
    const attachments = body?.attachments as
      | {
          images?: string[]; // data URLs æˆ–å…¬ç½‘é“¾æ¥
          files?: Array<{ name: string; content: string }>;
        }
      | undefined;

    if (!messages.length) {
      return new Response(
        JSON.stringify({ error: "è¯·æ±‚ä½“éœ€åŒ…å« messages æ•°ç»„" }),
        { status: 400 }
      );
    }

    // å¦‚æœæ²¡æœ‰ä¼šè¯IDï¼Œä¸ºç™»å½•ç”¨æˆ·åˆ›å»ºæ–°ä¼šè¯
    if (!conversationId && userId) {
      try {
        // ç”Ÿæˆå¯¹è¯æ ‡é¢˜ - ä½¿ç”¨AIç”Ÿæˆç®€æ´çš„æ ‡é¢˜
        const firstUserMsg = messages.find(m => m.role === 'user');
        let title = firstUserMsg?.content?.slice(0, 30) || "æ–°çš„å¯¹è¯";
        
        // ä½¿ç”¨AIå¼‚æ­¥ç”Ÿæˆæ›´å¥½çš„æ ‡é¢˜ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        setImmediate(async () => {
          try {
            if (firstUserMsg?.content) {
              const titleResponse = await fetch("https://api.openai.com/v1/chat/completions", {
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                  "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
                },
                body: JSON.stringify({
                  model: "gpt-3.5-turbo",
                  messages: [
                    {
                      role: "system",
                      content: "ä½ æ˜¯ä¸€ä¸ªæ ‡é¢˜ç”Ÿæˆä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ ‡é¢˜ï¼ˆä¸è¶…è¿‡20ä¸ªå­—ï¼‰ã€‚åªè¿”å›æ ‡é¢˜æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–æ ‡ç‚¹ç¬¦å·ã€‚"
                    },
                    {
                      role: "user",
                      content: firstUserMsg.content
                    }
                  ],
                  max_tokens: 30,
                  temperature: 0.7,
                }),
              });

              if (titleResponse.ok) {
                const titleData = await titleResponse.json();
                const generatedTitle = titleData.choices?.[0]?.message?.content?.trim();
                
                if (generatedTitle && conversationId) {
                  // æ›´æ–°æ ‡é¢˜åˆ°æ•°æ®åº“
                  const { updateConversationTitle } = await import("@/lib/database-hybrid");
                  await updateConversationTitle(conversationId, generatedTitle);
                  console.log("âœ… AI generated title:", generatedTitle);
                }
              }
            }
          } catch (error) {
            console.log("âš ï¸ Failed to generate AI title:", error);
          }
        });

        // ç›´æ¥ä½¿ç”¨æ··åˆå­˜å‚¨ï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†æ•°æ®åº“è¿æ¥çŠ¶æ€
        const { createConversation } = await import("@/lib/database-hybrid");
        const newConversation = await createConversation(userId, title);
        conversationId = newConversation.id;
        console.log("âœ… Created new conversation:", conversationId, "Initial title:", title);
      } catch (error) {
        console.error("âŒ Failed to create conversation:", error);
      }
    }

    // å¦‚éœ€è”ç½‘ï¼Œå…ˆæ£€ç´¢ç½‘ç»œå¹¶æ‹¼æ¥ä¸ºé¢å¤– system æç¤º
    async function buildWebContext(query: string | undefined): Promise<string | null> {
      if (!web || !process.env.TAVILY_API_KEY || !query) {
        console.log("Web search skipped:", { web, hasTavilyKey: !!process.env.TAVILY_API_KEY, hasQuery: !!query });
        return null;
      }
      
      // æ£€æŸ¥ç¼“å­˜
      const cacheKey = CACHE_KEYS.WEB_CONTEXT(query);
      const cached = cache.get<string>(cacheKey);
      if (cached) {
        console.log("Using cached web context for query:", query);
        return cached;
      }
      
      try {
        console.log("Starting web search for query:", query);
        const tavilyResponse = await fetch("https://api.tavily.com/search", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            api_key: process.env.TAVILY_API_KEY,
            query,
            search_depth: "basic",
            max_results: 6,
            include_images: false,
            include_answer: false,
          }),
        });
        
        if (!tavilyResponse.ok) {
          console.error("Tavily API error:", tavilyResponse.status, tavilyResponse.statusText);
          return null;
        }
        
        const tavily = await tavilyResponse.json();
        console.log("Tavily response:", tavily);
        
        const results = Array.isArray(tavily?.results) ? tavily.results.slice(0, 5) : [];
        if (!results.length) {
          console.log("No search results found");
          return null;
        }
        
        const lines = results.map((r: any, i: number) => 
          `ã€${i + 1}ã€‘${r?.title ?? "æ— æ ‡é¢˜"}\nå†…å®¹ï¼š${(r?.content ?? "").slice(0, 200)}...\næ¥æºï¼š${r?.url ?? ""}`
        ).join("\n\n");
        
        const webContext = `ğŸ“¡ è”ç½‘æœç´¢ç»“æœï¼ˆæœ€æ–°ä¿¡æ¯ï¼‰ï¼š\n\n${lines}\n\nâœ¨ è¯·åŸºäºä»¥ä¸Šæœ€æ–°ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¹¶åœ¨å›ç­”æœ«å°¾åˆ—å‡ºå‚è€ƒæ¥æºï¼š[1][2][3]ç­‰æ ¼å¼ã€‚`;
        
        // ç¼“å­˜ç»“æœï¼ˆ10åˆ†é’Ÿï¼‰
        cache.set(cacheKey, webContext, 10 * 60 * 1000);
        
        console.log("Web search completed, found", results.length, "results");
        return webContext;
      } catch (error) {
        console.error("Web search failed:", error);
        return null;
      }
    }

    const lastUserMsg = messages[messages.length - 1]?.content;

    // å¹¶è¡Œæ‰§è¡Œç½‘ç»œæœç´¢å’Œè®°å¿†æ£€ç´¢ä»¥å‡å°‘å»¶è¿Ÿ
    const [webContext, relevantMemories, searchResults] = await Promise.all([
      buildWebContext(lastUserMsg),
      // æ¢å¤è®°å¿†æ£€ç´¢ï¼Œä½†é™åˆ¶æ•°é‡ä»¥æé«˜é€Ÿåº¦ï¼Œå¹¶æ·»åŠ ç¼“å­˜
      userId ? getCachedMemories(userId, lastUserMsg || "") : Promise.resolve([]),
      // æ¢å¤è¯­ä¹‰æœç´¢ï¼Œä½†é™åˆ¶ç»“æœæ•°é‡ï¼Œå¹¶æ·»åŠ ç¼“å­˜
      getCachedSearchResults(lastUserMsg || "")
    ]);

    // ç¼“å­˜è®°å¿†æ£€ç´¢ç»“æœ
    async function getCachedMemories(userId: string, query: string): Promise<EmbeddingResult[]> {
      const cacheKey = CACHE_KEYS.USER_MEMORIES(userId, query);
      const cached = cache.get<EmbeddingResult[]>(cacheKey);
      if (cached) {
        console.log("Using cached memories for user:", userId);
        return cached;
      }

      try {
        const memories = await searchMemories(userId, query, 3);
        // ç¼“å­˜ç»“æœï¼ˆ5åˆ†é’Ÿï¼‰
        cache.set(cacheKey, memories, 5 * 60 * 1000);
        return memories;
      } catch (error) {
        console.error("Memory search failed:", error);
        return [];
      }
    }

    // ç¼“å­˜è¯­ä¹‰æœç´¢ç»“æœ
    async function getCachedSearchResults(query: string): Promise<SearchResult[]> {
      const cacheKey = CACHE_KEYS.SEARCH_RESULTS(query);
      const cached = cache.get<SearchResult[]>(cacheKey);
      if (cached) {
        console.log("Using cached search results for query:", query);
        return cached;
      }

      try {
        const results = await performSemanticSearch(query, 3);
        // ç¼“å­˜ç»“æœï¼ˆ10åˆ†é’Ÿï¼‰
        cache.set(cacheKey, results, 10 * 60 * 1000);
        return results;
      } catch (error) {
        console.error("Semantic search failed:", error);
        return [];
      }
    }

    async function buildOpenAIMessages(): Promise<ChatCompletionMessageParam[]> {
      // åŸºç¡€æ¶ˆæ¯
      // æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡
      let memoryContext = "";
      if (relevantMemories.length > 0) {
        memoryContext = "\n\nç›¸å…³è®°å¿†ä¿¡æ¯ï¼š\n" + 
          relevantMemories.map((memory, index) => 
            `${index + 1}. [${memory.category}] ${memory.content} (é‡è¦æ€§: ${memory.importance}/10)`
          ).join("\n") + 
          "\n\nè¯·æ ¹æ®è¿™äº›è®°å¿†ä¿¡æ¯æä¾›æ›´ä¸ªæ€§åŒ–çš„å›ç­”ã€‚";
      }

      // æ„å»ºæœç´¢ä¸Šä¸‹æ–‡
      let searchContext = "";
      if (searchResults.length > 0) {
        searchContext = "\n\nå®æ—¶æœç´¢ç»“æœï¼š\n" + 
          searchResults.map((result, index) => 
            `${index + 1}. ${result.title}\n   ${result.snippet}\n   æ¥æº: ${result.url}`
          ).join("\n\n") + 
          "\n\nè¯·ç»“åˆè¿™äº›æœç´¢ç»“æœæä¾›å‡†ç¡®å’Œæœ€æ–°çš„ä¿¡æ¯ï¼Œå¹¶åœ¨å›ç­”æœ«å°¾æä¾›å‚è€ƒé“¾æ¥ã€‚";
      }

      // è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
      const now = new Date();
      const dateString = now.toLocaleDateString('zh-CN', {
        year: 'numeric',
        month: 'long',
        day: 'numeric',
        weekday: 'long'
      });
      const currentDateTime = `å½“å‰æ—¥æœŸæ—¶é—´ï¼š${dateString} ${now.toLocaleTimeString('zh-CN', { hour12: false })}`;

      const systemPrompt =
        body?.systemPrompt ||
        (userLang === "en"
          ? `${now.toLocaleString('en-US')}. You are a helpful AI assistant. Respond concisely and accurately.` + memoryContext + searchContext
          : userLang === "ja"
          ? `${now.toLocaleString('ja-JP')}ã€‚ã‚ãªãŸã¯å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚` + memoryContext + searchContext
          : userLang === "ko"
          ? `${now.toLocaleString('ko-KR')}. ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.` + memoryContext + searchContext
          : `${currentDateTime}ã€‚ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©ç†ã€‚ç”¨ç®€ä½“ä¸­æ–‡å›ç­”ï¼Œç®€æ´å‡†ç¡®ã€‚` + memoryContext + searchContext);

      const oaMessages: ChatCompletionMessageParam[] = [
        { role: "system", content: systemPrompt },
        ...messages.map((m) => ({ role: m.role, content: m.content } as ChatCompletionMessageParam)),
      ];
      // é™„ä»¶ï¼šå°†æœ€åä¸€æ¡ user æ¶ˆæ¯å‡çº§ä¸ºå¤šæ¨¡æ€
      const imgs = Array.isArray(attachments?.images) ? attachments!.images.slice(0, 4) : [];
      const files = Array.isArray(attachments?.files) ? attachments!.files : [];
      if (imgs.length || files.length) {
        const lastIndex = oaMessages.length - 1;
        if (lastIndex >= 0 && oaMessages[lastIndex]?.role === "user") {
          const last = oaMessages[lastIndex];
          const textParts: any[] = [];
          // æ–‡æœ¬éƒ¨åˆ†ï¼šåŸå§‹æé—® + æ–‡ä»¶å†…å®¹ï¼ˆæˆªæ–­ï¼‰
          const fileText = files
            .map((f) => {
              const clipped = (f.content ?? "").slice(0, 50_000); // é™åˆ¶ä½“ç§¯
              // æ£€æŸ¥æ˜¯å¦æ˜¯PDFæ–‡ä»¶
              if (f.name.toLowerCase().endsWith('.pdf')) {
                return `ã€PDFæ–‡ä»¶:${f.name}ã€‘\n${clipped}\n\næ³¨æ„ï¼šè¿™æ˜¯PDFæ–‡ä»¶çš„å†…å®¹ï¼Œå¦‚æœå†…å®¹æ˜¾ç¤ºä¸å®Œæ•´ï¼Œå»ºè®®æ‚¨å°†PDFå†…å®¹å¤åˆ¶ç²˜è´´åˆ°èŠå¤©æ¡†ä¸­ä»¥è·å¾—æ›´å‡†ç¡®çš„åˆ†æã€‚`;
              }
              return `ã€æ–‡ä»¶:${f.name}ã€‘\n${clipped}`;
            })
            .join("\n\n");
          const fullText = typeof (last as any).content === "string" ? (last as any).content : "";
          const mergedText = fileText ? `${fullText}\n\n${fileText}` : fullText;
          textParts.push({ type: "text", text: mergedText });
                  // å›¾ç‰‡éƒ¨åˆ† - åŒæ­¥åˆ†æå›¾ç‰‡ï¼Œç¡®ä¿AIèƒ½çœ‹åˆ°å›¾ç‰‡å†…å®¹
                  if (imgs.length > 0) {
                    try {
                      console.log("ğŸ–¼ï¸ å¼€å§‹åˆ†æå›¾ç‰‡ï¼Œæ•°é‡:", imgs.length);

                      // æ£€æŸ¥æ˜¯å¦æœ‰OpenAI APIå¯†é’¥
                      const openaiKey = process.env.OPENAI_API_KEY;
                      if (!openaiKey || openaiKey.length < 20) {
                        console.log("âš ï¸ OpenAI APIå¯†é’¥æ— æ•ˆï¼Œè·³è¿‡å›¾ç‰‡åˆ†æ");
                        textParts.push({
                          type: "text",
                          text: `\n\n[ç”¨æˆ·ä¸Šä¼ äº† ${imgs.length} å¼ å›¾ç‰‡ï¼Œä½†å›¾ç‰‡åˆ†ææœåŠ¡ä¸å¯ç”¨]`
                        });
                      } else {
                        // ä½¿ç”¨OpenAI Vision APIåˆ†æå›¾ç‰‡
                        const openaiVision = new OpenAI({
                          apiKey: process.env.OPENAI_API_KEY,
                          baseURL: "https://api.openai.com/v1",
                        });

                        // éªŒè¯å’Œå¤„ç†å›¾ç‰‡URLæ ¼å¼
                        const validImgs = imgs.filter((imgUrl, index) => {
                          const isDataUrl = imgUrl.startsWith('data:image/');
                          const isHttpUrl = imgUrl.startsWith('http://') || imgUrl.startsWith('https://');

                          if (isDataUrl) {
                            const supportedFormats = ['png', 'jpeg', 'jpg', 'gif', 'webp'];
                            return supportedFormats.some(format =>
                              imgUrl.startsWith(`data:image/${format}`)
                            );
                          }
                          return isHttpUrl;
                        });

                        if (validImgs.length === 0) {
                          console.log("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ ¼å¼");
                          textParts.push({
                            type: "text",
                            text: `\n\n[ç”¨æˆ·ä¸Šä¼ äº† ${imgs.length} å¼ å›¾ç‰‡ï¼Œä½†æ ¼å¼ä¸æ”¯æŒ]`
                          });
                        } else {
                          // åŒæ­¥åˆ†æå›¾ç‰‡
                          const visionCompletion = await openaiVision.chat.completions.create({
                            model: "gpt-4o",
                            messages: [
                              {
                                role: "user",
                                content: [
                                  {
                                    type: "text",
                                    text: "è¯·è¯¦ç»†åˆ†æè¿™äº›å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š1. å›¾ç‰‡ä¸­æ˜¾ç¤ºçš„ä¸»è¦ç‰©ä½“å’Œæ–‡å­— 2. é¢œè‰²å’Œæ„å›¾ 3. å¯èƒ½çš„ç”¨é€”æˆ–åœºæ™¯ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¦å‡†ç¡®æè¿°å›¾ç‰‡å†…å®¹ã€‚"
                                  },
                                  ...validImgs.slice(0, 2).map(imgUrl => ({ // é™åˆ¶æœ€å¤š2å¼ å›¾ç‰‡
                                    type: "image_url" as const,
                                    image_url: { url: imgUrl }
                                  }))
                                ]
                              }
                            ],
                            max_tokens: 1000
                          });

                          const visionAnalysis = visionCompletion.choices[0]?.message?.content || "æ— æ³•åˆ†æå›¾ç‰‡å†…å®¹";
                          console.log("âœ… å›¾ç‰‡åˆ†æå®Œæˆ:", visionAnalysis.substring(0, 100) + "...");
                          
                          // å°†å›¾ç‰‡åˆ†æç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                          textParts.push({
                            type: "text",
                            text: `\n\n[å›¾ç‰‡åˆ†æç»“æœï¼š${visionAnalysis}]`
                          });
                        }
                      }
                    } catch (visionError) {
                      console.error("âŒ å›¾ç‰‡åˆ†æå¤±è´¥:", visionError);
                      textParts.push({
                        type: "text",
                        text: `\n\n[ç”¨æˆ·ä¸Šä¼ äº† ${imgs.length} å¼ å›¾ç‰‡ï¼Œä½†åˆ†æå¤±è´¥]`
                      });
                    }
                  }
          oaMessages[lastIndex] = { role: "user", content: textParts } as any;
        }
      }
      if (webContext) oaMessages.push({ role: "system", content: webContext });
    return oaMessages;
  }

  // å¤„ç†å›¾ç‰‡åˆ†æç»“æœ
  function processImageAnalysis(visionData: any): string {
    const responses = visionData.responses?.[0];
    if (!responses) return "æ— æ³•åˆ†ææ­¤å›¾ç‰‡";

    const labels = responses.labelAnnotations || [];
    const texts = responses.textAnnotations || [];
    const objects = responses.localizedObjectAnnotations || [];

    let analysis = "";
    
    if (labels.length > 0) {
      analysis += `æ£€æµ‹åˆ°ï¼š${labels.map((l: any) => l.description).join(", ")}`;
    }
    
    if (texts.length > 0) {
      const textContent = texts.map((t: any) => t.description).join(" ");
      analysis += `ã€‚æ–‡å­—å†…å®¹ï¼š${textContent}`;
    }
    
    if (objects.length > 0) {
      analysis += `ã€‚ç‰©ä½“ï¼š${objects.map((o: any) => o.name).join(", ")}`;
    }

    return analysis || "å›¾ç‰‡åˆ†æå®Œæˆï¼Œä½†æœªæ£€æµ‹åˆ°æ˜æ˜¾ç‰¹å¾";
  }

    // æµå¼è¾“å‡º
    if (stream) {
      const encoder = new TextEncoder();
      const streamBody = new ReadableStream<Uint8Array>({
        async start(controller) {
          try {
      const oaMessages = await buildOpenAIMessages();
            const streamCompletion = await openai.chat.completions.create({
              model,
              messages: oaMessages,
              temperature,
              presence_penalty: 0.1,
              frequency_penalty: 0.15,
              // å¤§å¹…æå‡tokené™åˆ¶ï¼Œç¡®ä¿å›ç­”å®Œæ•´æ€§
              max_tokens: 8192,
              stream: true,
            });
            console.log('âœ… å¼€å§‹æµå¼ç”Ÿæˆï¼Œæ¨¡å‹:', model);
            // ç´¯ç§¯å†…å®¹ç”¨äºä¿å­˜
            let fullText = "";
            let tokenCount = 0;
            let buffer = "";
            let isStreamComplete = false;

            for await (const part of streamCompletion as any) {
              const token = part?.choices?.[0]?.delta?.content ?? "";
              const finishReason = part?.choices?.[0]?.finish_reason;

              // æ£€æŸ¥æµæ˜¯å¦å®Œæˆ
              if (finishReason) {
                console.log(`âœ… æµå¼ç”Ÿæˆå®Œæˆï¼ŒåŸå› : ${finishReason}, æ€»tokenæ•°: ${tokenCount}`);
                isStreamComplete = true;
              }

              if (token) {
                fullText += token;
                tokenCount++;
                buffer += token;

                // æ‰¹é‡å‘é€tokenä»¥æé«˜æ€§èƒ½ï¼Œæ¯5ä¸ªtokenæˆ–é‡åˆ°æ ‡ç‚¹ç¬¦å·æ—¶å‘é€
                const shouldFlush = tokenCount % 5 === 0 ||
                  /[ã€‚ï¼ï¼Ÿ\n]/.test(token) ||
                  buffer.length > 30;

                if (shouldFlush) {
                  controller.enqueue(encoder.encode(buffer));
                  buffer = "";
                }

                // æ¯100ä¸ªtokenè®°å½•ä¸€æ¬¡è¿›åº¦
                if (tokenCount % 100 === 0) {
                  console.log(`ğŸ“ å·²ç”Ÿæˆ ${tokenCount} tokens, ${fullText.length} å­—ç¬¦`);
                }
              }
            }

            // å‘é€å‰©ä½™çš„buffer
            if (buffer) {
              controller.enqueue(encoder.encode(buffer));
              buffer = "";
            }

            console.log(`âœ… æµå¼ä¼ è¾“å®Œæˆ - æ€»è®¡: ${tokenCount} tokens, ${fullText.length} å­—ç¬¦`);
            // è¿½åŠ å‚è€ƒé“¾æ¥ï¼ˆè‹¥å¼€å¯è”ç½‘ï¼‰
            if (searchResults && searchResults.length > 0) {
              try {
                const references = searchResults.map((result, index) => ({
                  url: result.url,
                  title: result.title
                }));
                
                const refText = references.map((_, i) => `[${i + 1}]`).join('');
                const appendix = `\n\nå‚è€ƒæ¥æºï¼š${refText}`;
                fullText += appendix;
                controller.enqueue(encoder.encode(appendix));
                
                // åœ¨æµå¼å“åº”ç»“æŸæ—¶å‘é€å‚è€ƒé“¾æ¥æ•°æ®
                const refData = JSON.stringify({ type: 'references', data: references });
                controller.enqueue(encoder.encode(`\n\n<ref-data>${refData}</ref-data>`));
              } catch (error) {
                console.error("å¤„ç†æµå¼å‚è€ƒé“¾æ¥å¤±è´¥:", error);
              }
            }
            // ä¿å­˜æ¶ˆæ¯ï¼ˆç”¨æˆ·+åŠ©æ‰‹ï¼‰- åªæœ‰ç™»å½•ç”¨æˆ·æ‰ä¿å­˜
            if (conversationId && userId) {
              try {
                // ä½¿ç”¨æ··åˆå­˜å‚¨ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®åº“è¿æ¥çŠ¶æ€
                const { createMessage } = await import("@/lib/database-hybrid");
                await createMessage(conversationId, "user", messages[messages.length - 1]?.content || "");
                await createMessage(conversationId, "assistant", fullText);
                console.log("âœ… Messages saved for user:", userId);

                // å¼‚æ­¥æå–è®°å¿†ï¼Œä¸é˜»å¡å“åº”
                setImmediate(async () => {
                  try {
                    await extractMemoriesFromConversation(userId, conversationId, messages);
                    console.log("ğŸ§  Memories extracted for conversation:", conversationId);
                  } catch (error) {
                    console.error("Error extracting memories:", error);
                  }
                });
              } catch (error) {
                console.error("âŒ Failed to save messages:", error);
              }
            } else {
              console.log("âš ï¸ Skipping message save - no conversationId or userId");
            }
          } catch (err: any) {
            const msg = err?.message || "æµå¼ç”Ÿæˆå¤±è´¥";
            controller.enqueue(encoder.encode(`\n[ERROR] ${msg}`));
          } finally {
            controller.close();
          }
        },
      });
      return new Response(streamBody, {
        headers: {
          "Content-Type": "text/plain; charset=utf-8",
          "Cache-Control": "no-cache",
          "X-Conversation-Id": conversationId || "",
        },
      });
    }

    // å…¼å®¹ openai v5ï¼šä¼˜å…ˆä½¿ç”¨æ–°çš„ responses APIï¼ˆè‹¥éƒ¨ç½²ç¯å¢ƒæ”¯æŒï¼‰ï¼Œå¦åˆ™å›é€€åˆ° chat.completions
    let choice: any = null;
    let usage: any = null;
    try {
      // å¦‚åŒ…å«å›¾ç‰‡ï¼Œè·³è¿‡ responses APIï¼ˆDeepSeekä¸æ”¯æŒå›¾ç‰‡ï¼‰
      const hasImages = Array.isArray(attachments?.images) && attachments!.images.length > 0;
      if (hasImages) throw new Error("skip-responses-for-images");
      // @ts-ignore: éƒ¨åˆ†è¿è¡Œç¯å¢ƒå¯èƒ½ä¸å­˜åœ¨ responses API
      const response = await (openai as any).responses?.create?.({
        model,
        input: messages,
        temperature,
      });
      const output = response?.output_text ?? response?.content?.[0]?.text;
      if (output) {
        choice = { role: "assistant", content: output };
      }
      usage = (response as any)?.usage ?? null;
    } catch (_) {
      // å¿½ç•¥ï¼Œå›é€€åˆ° chat.completions
    }

    if (!choice) {
      const oaMessages = await buildOpenAIMessages();
      const completion = await openai.chat.completions.create({
        model,
        messages: oaMessages,
        temperature,
        presence_penalty: 0.1,
        frequency_penalty: 0.2,
        // å¤§å¹…æå‡tokené™åˆ¶ï¼Œç¡®ä¿å›ç­”å®Œæ•´æ€§
        max_tokens: 8192,
      });
      choice = completion.choices?.[0]?.message;
      usage = (completion as any)?.usage ?? null;
      // è‹¥å¼€å¯è”ç½‘ï¼šä»æœç´¢ç»“æœä¸­æå–å‚è€ƒé“¾æ¥
      if (searchResults && searchResults.length > 0 && typeof choice?.content === "string") {
        try {
          const references = searchResults.map((result, index) => ({
            url: result.url,
            title: result.title
          }));
          
          // å°†å‚è€ƒé“¾æ¥æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
          choice.references = references;
          
          // åœ¨å†…å®¹æœ«å°¾æ·»åŠ æ•°å­—å¼•ç”¨
          const refText = references.map((_, i) => `[${i + 1}]`).join('');
          choice.content = `${choice.content}\n\nå‚è€ƒæ¥æºï¼š${refText}`;
        } catch (error) {
          console.error("å¤„ç†å‚è€ƒé“¾æ¥å¤±è´¥:", error);
        }
      }
      // ä¿å­˜æ¶ˆæ¯ä¸ç”¨é‡ - åªæœ‰ç™»å½•ç”¨æˆ·æ‰ä¿å­˜
      if (conversationId && userId) {
        try {
          // ä½¿ç”¨æ··åˆå­˜å‚¨ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®åº“è¿æ¥çŠ¶æ€
          const { createMessage } = await import("@/lib/database-hybrid");
          await createMessage(conversationId, "user", messages[messages.length - 1]?.content || "");
          await createMessage(conversationId, "assistant", choice?.content || "");
          console.log("âœ… Messages saved for user (non-stream):", userId);

          // å¼‚æ­¥æå–è®°å¿†ï¼Œä¸é˜»å¡å“åº”
          setImmediate(async () => {
            try {
              await extractMemoriesFromConversation(userId, conversationId, messages);
              console.log("ğŸ§  Memories extracted for conversation:", conversationId);
            } catch (error) {
              console.error("Error extracting memories:", error);
            }
          });
        } catch (error) {
          console.error("âŒ Failed to save messages (non-stream):", error);
        }
      } else {
        console.log("âš ï¸ Skipping message save (non-stream) - no conversationId or userId");
      }
    }
    if (!choice) {
      return new Response(
        JSON.stringify({ error: "æœªè·å–åˆ°æ¨¡å‹å›å¤" }),
        { status: 502 }
      );
    }

    // è§„èŒƒåŒ– usage å­—æ®µ
    const normalizedUsage = usage
      ? {
          prompt_tokens:
            (usage as any).prompt_tokens ?? (usage as any).input_tokens ?? null,
          completion_tokens:
            (usage as any).completion_tokens ?? (usage as any).output_tokens ?? null,
          total_tokens: (usage as any).total_tokens ?? null,
        }
      : null;

    return new Response(
      JSON.stringify({ 
        reply: choice, 
        usage: normalizedUsage,
        conversationId: conversationId || null 
      }),
      { headers: { "Content-Type": "application/json" } }
    );
  } catch (error: unknown) {
    console.error("âŒ Chat API error:", error);
    const message =
      error instanceof Error ? error.message : "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯";
    
    // æ ¹æ®é”™è¯¯ç±»å‹è¿”å›ä¸åŒçš„çŠ¶æ€ç 
    let status = 500;
    if (message.includes("402") || message.includes("Insufficient Balance")) {
      status = 402;
    } else if (message.includes("401") || message.includes("Unauthorized")) {
      status = 401;
    } else if (message.includes("429") || message.includes("Rate limit")) {
      status = 429;
    }
    
    return new Response(
      JSON.stringify({ 
        error: message,
        type: status === 402 ? "insufficient_balance" : 
              status === 401 ? "unauthorized" :
              status === 429 ? "rate_limit" : "server_error"
      }),
      { status }
    );
  }
}


